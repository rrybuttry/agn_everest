{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computes the correlation coefficient between C8 and C16\n",
    "\n",
    "cannot be run without hdf5 file contain all C8 and C16 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis import *\n",
    "import h5py\n",
    "from astropy.convolution import convolve, Box1DKernel\n",
    "import sys\n",
    "\n",
    "#if __name__==\"__main__\":\n",
    "\n",
    "for channel in range(5,85):\n",
    "\n",
    "    campaign = 8\n",
    "    mod,submod = get_submod(channel)\n",
    "    submod-=1 # submods are 0-3 in the hdf5 file\n",
    "\n",
    "    #hdf5_file = \"/Users/rachelbuttry/K2/K2C%s_target_pixels.hdf5\"%campaign\n",
    "    hdf5_file = \"/home/jackeline/Research/k2_pipeline/k2_LongTermSystematics/data/pixelmaps/k2pixelmap.hdf5\"\n",
    "\n",
    "    #hdf5_file = \"/home/rachel/Research/K2/K2C%s_target_pixels.hdf5\"%campaign\n",
    "    # there are 23117 objects in the campaign 8 hdf5 file\n",
    "    # there are 3853 cadence points in c8\n",
    "    cadences = 3853\n",
    "    time = np.arange(cadences)/48.0\n",
    "    \n",
    "    try:\n",
    "        with h5py.File(hdf5_file, 'r') as f:\n",
    "            channel_epics = np.array(list(f['%s/%s/%s'%(campaign, mod,submod)].keys()))# look at objects in given channel).astype(int)\n",
    "\n",
    "        # need the kepler magnitudes\n",
    "        #all_targets = pd.read_csv(\"./K2_official_targets/K2Campaign%stargets.csv\"%campaign, skipinitialspace=True)\n",
    "        all_targets = pd.read_csv(\"/home/jackeline/Research/k2_pipeline/K2_official_targets/K2Campaign%stargets.csv\"%campaign, skipinitialspace=True)\n",
    "\n",
    "\n",
    "        # saving lcs to take the median\n",
    "        arr = []\n",
    "\n",
    "        with h5py.File(hdf5_file, 'r') as f:\n",
    "            channel_epics = np.array(list(f['%s/%s/%s'%(campaign, mod, submod)].keys()))# look at objects in given channel).astype(int)\n",
    "\n",
    "            rel_epics = channel_epics[np.isin(channel_epics, all_targets['EPIC ID'][np.logical_and(all_targets['magnitude'] > 13, all_targets['magnitude'] < 20)])]\n",
    "            #print(len(rel_epics))\n",
    "\n",
    "            # loop thru the objects\n",
    "            for epic in rel_epics:\n",
    "                d = np.array(f['%s/%s/%s/%s'%(campaign, mod, submod, epic)]['data'])\n",
    "                lc_hdf5 = np.nansum(np.nansum(d, axis=1), axis=1)\n",
    "\n",
    "                # handle spurious cadences\n",
    "                lc = lk.LightCurve(time, flux=lc_hdf5)\n",
    "                _, spurious_cad = lc.flatten().remove_outliers(return_mask=True) # remove spurious cadences\n",
    "                lc_raw = lc.flux\n",
    "\n",
    "                # interpolate\n",
    "                cadno = np.arange(len(lc_raw)) # get an array to serve as our time/cadence measurement\n",
    "                interped_vals = np.interp(cadno[spurious_cad], cadno[~spurious_cad], lc_raw[~spurious_cad])\n",
    "                # replace spurious cadence values with the interpolated values\n",
    "                lc_raw[spurious_cad] = interped_vals\n",
    "                norm = np.std(lc_raw)\n",
    "                lc_raw -= np.mean(lc_raw)\n",
    "                lc_raw = lc_raw/norm\n",
    "                #lc_raw = lc_raw/np.max(np.abs(lc_raw))\n",
    "\n",
    "                smooth = convolve(lc_raw, Box1DKernel(350), boundary='extend')\n",
    "\n",
    "                arr.append(lc_raw)\n",
    "\n",
    "        cmap = plt.get_cmap('inferno')\n",
    "        mag_colors = np.zeros((len(cmap.colors),4))\n",
    "        mag_colors[:,3] = 0.7 #this is the alpha parameter\n",
    "        mag_colors[:,:3] = cmap.colors\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #fig = plt.figure(figsize=(8,5))\n",
    "\n",
    "        p= 50\n",
    "        flux = np.percentile(np.atleast_2d(np.array(arr)),p, axis=0)\n",
    "        flux_smooth = convolve(flux, Box1DKernel(250), boundary='extend')\n",
    "        #plt.plot(time, flux, linewidth=4, alpha=0.8, color=\"#fee6ce\")\n",
    "        #plt.plot(time, flux_smooth-flux_smooth.mean(), linewidth=10, color=\"#e6550d\" )\n",
    "        lcList[channel]  =  flux_smooth\n",
    "\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcList[channel]  =  flux_smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import cPickle as pickle\n",
    "except ImportError:  # Python 3.x\n",
    "    import pickle\n",
    "\n",
    "with open('c8_fig4_lcs.p', 'wb') as fp:\n",
    "    pickle.dump(lcList, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc16List = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no data for channel 5\n",
      "no data for channel 6\n",
      "no data for channel 7\n",
      "no data for channel 8\n",
      "no data for channel 9\n",
      "no data for channel 10\n",
      "no data for channel 11\n",
      "no data for channel 12\n",
      "no data for channel 17\n",
      "no data for channel 18\n",
      "no data for channel 19\n",
      "no data for channel 20\n"
     ]
    }
   ],
   "source": [
    "for channel in range(2,85):\n",
    "\n",
    "    campaign = 16\n",
    "    mod,submod = get_submod(channel)\n",
    "    submod-=1 # submods are 0-3 in the hdf5 file\n",
    "\n",
    "    #hdf5_file = \"/Users/rachelbuttry/K2/K2C%s_target_pixels.hdf5\"%campaign\n",
    "    hdf5_file = \"/home/jackeline/Dropbox/Kepler/K2PixelMap_c16.hdf5\"\n",
    "\n",
    "    #hdf5_file = \"/home/rachel/Research/K2/K2C%s_target_pixels.hdf5\"%campaign\n",
    "    # there are 3894 cadence points in c16\n",
    "    cadences = 3894\n",
    "    time = np.arange(cadences)/48.0\n",
    "    try:\n",
    "        \n",
    "        with h5py.File(hdf5_file, 'r') as f:\n",
    "            channel_epics = np.array(list(f['%s/%s/%s'%(campaign, mod,submod)].keys()))# look at objects in given channel).astype(int)\n",
    "\n",
    "        # need the kepler magnitudes\n",
    "        all_targets = pd.read_csv(\"/home/jackeline/Research/k2_pipeline/K2_official_targets/K2Campaign%stargets.csv\"%campaign, skipinitialspace=True)\n",
    "\n",
    "        # saving lcs to take the median\n",
    "        arr = []\n",
    "\n",
    "        with h5py.File(hdf5_file, 'r') as f:\n",
    "            channel_epics = np.array(list(f['%s/%s/%s'%(campaign, mod, submod)].keys()))# look at objects in given channel).astype(int)\n",
    "\n",
    "            rel_epics = channel_epics[np.isin(channel_epics, all_targets['EPIC ID'][np.logical_and(all_targets['magnitude'] > 13, all_targets['magnitude'] < 20)])]\n",
    "            #print(len(rel_epics))\n",
    "\n",
    "            # loop thru the objects\n",
    "            for epic in rel_epics:\n",
    "                d = np.array(f['%s/%s/%s/%s'%(campaign, mod, submod, epic)]['data'])\n",
    "                lc_hdf5 = np.nansum(np.nansum(d, axis=1), axis=1)\n",
    "\n",
    "                # handle spurious cadences\n",
    "                lc = lk.LightCurve(time, flux=lc_hdf5)\n",
    "                _, spurious_cad = lc.flatten().remove_outliers(return_mask=True) # remove spurious cadences\n",
    "                lc_raw = lc.flux\n",
    "\n",
    "                # interpolate\n",
    "                cadno = np.arange(len(lc_raw)) # get an array to serve as our time/cadence measurement\n",
    "                interped_vals = np.interp(cadno[spurious_cad], cadno[~spurious_cad], lc_raw[~spurious_cad])\n",
    "                # replace spurious cadence values with the interpolated values\n",
    "                lc_raw[spurious_cad] = interped_vals\n",
    "                norm = np.std(lc_raw)\n",
    "                lc_raw -= np.mean(lc_raw)\n",
    "                lc_raw = lc_raw/norm\n",
    "\n",
    "                smooth = convolve(lc_raw, Box1DKernel(350), boundary='extend')\n",
    "\n",
    "                arr.append(lc_raw)\n",
    "\n",
    "        #flux = np.nanmedian(np.atleast_2d(np.array(arr)), axis=0)\n",
    "        #flux_smooth = convolve(flux, Box1DKernel(250), boundary='extend')\n",
    "\n",
    "        #fig = plt.figure(figsize=(8,5))\n",
    "        #plt.plot(time, flux[::-1], linewidth=4, alpha=0.8, color=\"#9ebcda\")\n",
    "        #plt.plot(time, flux_smooth[::-1], linewidth=10, color=\"#8856a7\")\n",
    "\n",
    "        #uncomment everything above to revert back \n",
    "\n",
    "\n",
    "\n",
    "        #fig = plt.figure(figsize=(8,5))\n",
    "\n",
    "        p = 50\n",
    "        flux = np.percentile(np.atleast_2d(np.array(arr)),p, axis=0)\n",
    "        flux_smooth = convolve(flux, Box1DKernel(250), boundary='extend')\n",
    "        #plt.plot(time, flux[::-1], linewidth=4, alpha=0.8, color=\"#9ebcda\")\n",
    "        #plt.plot(time, (flux_smooth-flux_smooth.mean())[::-1], linewidth=10,  color=\"#8856a7\")\n",
    "        lc16List[channel] = flux_smooth\n",
    "    except:\n",
    "        print(\"no data for channel\",channel)\n",
    "        pass\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lc16List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import cPickle as pickle\n",
    "except ImportError:  # Python 3.x\n",
    "    import pickle\n",
    "\n",
    "with open('c16_fig4_lcs.p', 'wb') as fp:\n",
    "    pickle.dump(lc16List, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.9101559407342444 0.0\n",
      "3 0.7578638194956553 0.0\n",
      "4 0.7365823124278774 0.0\n",
      "13 0.8291466110384835 0.0\n",
      "14 0.7629735962387325 0.0\n",
      "15 0.2678515416122086 2.65254269774184e-64\n",
      "16 0.847434840384153 0.0\n",
      "21 0.8270160403483373 0.0\n",
      "22 0.9448217913757206 0.0\n",
      "23 0.8028211663612919 0.0\n",
      "24 0.7923335565250504 0.0\n",
      "25 -0.1277767012548306 1.6996040504085149e-15\n",
      "26 0.696593156902126 0.0\n",
      "27 0.20610220052954076 3.1215841812791796e-38\n",
      "28 0.657185826039909 0.0\n",
      "29 0.7773671797367858 0.0\n",
      "30 0.5506510541217602 1.789844640043413e-304\n",
      "31 0.5203058311238016 2.4983710760755033e-266\n",
      "32 0.44228067232088586 2.7336591444292944e-184\n",
      "33 0.8664449372610151 0.0\n",
      "34 0.1519651403958161 2.4253227387899374e-21\n",
      "35 0.6702332524722161 0.0\n",
      "36 -0.09001914667358177 2.177530349531829e-08\n",
      "37 0.8979633999410805 0.0\n",
      "38 0.5784311306246581 0.0\n",
      "39 -0.14363229822190404 3.269881529523216e-19\n",
      "40 0.42221054247679546 2.0065300449116835e-166\n",
      "41 0.9176351705961507 0.0\n",
      "42 0.8151313830614761 0.0\n",
      "43 0.848231363000705 0.0\n",
      "44 0.9671651823969095 0.0\n",
      "45 -0.1836701753009287 1.3962839931917965e-30\n",
      "46 0.47949650585826004 9.03854357062604e-221\n",
      "47 0.6118685903402554 0.0\n",
      "48 0.19165113127096384 3.391657165465591e-33\n",
      "49 0.8998793314281435 0.0\n",
      "50 -0.16252076883236466 3.2342129659100694e-24\n",
      "51 0.8471511358318876 0.0\n",
      "52 0.1710408617382028 1.1050265077304195e-26\n",
      "53 0.9035093700007382 0.0\n",
      "54 0.9126807056618208 0.0\n",
      "55 0.7123875092928242 0.0\n",
      "56 0.8803652255367308 0.0\n",
      "57 0.9587651915389582 0.0\n",
      "58 0.7089309042330515 0.0\n",
      "59 0.05673875018465116 0.0004257037822303733\n",
      "60 0.10471281572753713 7.23998513071182e-11\n",
      "61 0.4382749600317925 1.2576723738406857e-180\n",
      "62 -0.1630708579562112 2.2619236868564998e-24\n",
      "63 0.6182990528919291 0.0\n",
      "64 0.5653415584397506 0.0\n",
      "65 0.4673862046790962 2.125434494160422e-208\n",
      "66 0.9501260161069055 0.0\n",
      "67 0.20672669884768474 1.8530704332088759e-38\n",
      "68 0.216699210031923 3.554367616838345e-42\n",
      "69 0.5312398448935103 1.2584138182535915e-279\n",
      "70 0.31466001715379477 2.646718875798214e-89\n",
      "71 0.6449213329439712 0.0\n",
      "72 0.24788470042145716 4.816708038249084e-55\n",
      "73 0.7746649131947516 0.0\n",
      "74 0.7701571093866428 0.0\n",
      "75 0.49297730543479934 3.851704232765846e-235\n",
      "76 0.12895467942323086 9.318474831885886e-16\n",
      "77 0.6086853171985698 0.0\n",
      "78 -0.07457374201289099 3.587836632393191e-06\n",
      "79 0.9531815571062656 0.0\n",
      "80 0.9118831935546032 0.0\n",
      "81 0.3539771712677875 4.0669585194808996e-114\n",
      "82 0.17918633467431475 3.650944878115453e-29\n",
      "83 0.19305128783897954 1.1469787024380997e-33\n",
      "84 0.8793087222502873 0.0\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "chList = []\n",
    "rList = []\n",
    "\n",
    "\n",
    "\n",
    "for key in lc16List.keys():\n",
    "    #print(len(lcList[key]), len(lc16List[key]))\n",
    "    lc8 = lcList[key]\n",
    "    lc16 = lc16List[key][:len(lcList[key])][::-1]\n",
    "    r, p = stats.pearsonr(lc8 - lc8.mean(), lc16-lc16.mean())\n",
    "    #f, ax = plt.subplots(1,1)\n",
    "    #ax.plot(lc8)\n",
    "    #ax.plot(lc16)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pd.DataFrame(np.array(rList).reshape(1,71), columns = chList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.to_csv(\"CorrelationCoeff_16_8.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
